{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, datasets\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torchnet.meter.confusionmeter as cm\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path=r\"/home/woody/iwi5/iwi5095h/CNN-multiclass-classification-results/checkpoint/resnet/fold_1/model_ft.pt\"\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_ft = models.resnet18()\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = torch.nn.Linear(num_ftrs, 7)\n",
    "    # model_ft=torch.load(ckpt_path)['model_state_dict']\n",
    "    state = torch.load(ckpt_path, map_location=torch.device(device))\n",
    "    model_ft.load_state_dict(state[\"model_state_dict\"])\n",
    "    model_ft.eval()\n",
    "    return model_ft\n",
    "\n",
    "model_ft = load_model()\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_as_windows_new(arr_in, window_shape):\n",
    "    ndim = arr_in.ndim\n",
    "\n",
    "    if isinstance(window_shape, numbers.Number):\n",
    "        window_shape = (window_shape,) * ndim\n",
    "    if not (len(window_shape) == ndim):\n",
    "        raise ValueError(\"`window_shape` is incompatible with `arr_in.shape`\")\n",
    "\n",
    "    arr_shape = np.array(arr_in.shape)\n",
    "    plt.imshow(arr_in,cmap='gray')\n",
    "    window_shape = np.array(window_shape, dtype=arr_shape.dtype)\n",
    "\n",
    "    if (window_shape > arr_shape).any():\n",
    "        # padd with zeros in that direction\n",
    "        if window_shape[0] > arr_shape[0]:\n",
    "            top = int((window_shape[0] - arr_shape[0]) / 2)\n",
    "            bottom = window_shape[0] - arr_shape[0] - top\n",
    "            arr_in = cv2.copyMakeBorder(\n",
    "                arr_in, top, bottom, 0, 0, cv2.BORDER_REPLICATE, value=0\n",
    "            )\n",
    "\n",
    "        elif window_shape[1] > arr_shape[1]:\n",
    "            left = int((window_shape[1] - arr_shape[1]) / 2)\n",
    "            right = window_shape[1] - arr_shape[1] - left\n",
    "            arr_in = cv2.copyMakeBorder(\n",
    "                arr_in, 0, 0, left, right, cv2.BORDER_REPLICATE, value=0\n",
    "            )\n",
    "\n",
    "    arr_shape = np.array(arr_in.shape)\n",
    "\n",
    "    patch_shape = (955, 783)\n",
    "    num_patches_x, num_patches_y = [\n",
    "        int(np.ceil(arr_in.shape[i] / patch_shape[i])) for i in range(ndim)\n",
    "    ]\n",
    "    print(\"num_patches_x\", num_patches_x)\n",
    "    print(\"num_patches_y\", num_patches_y)\n",
    "    arr_out = da.from_array(arr_in, chunks=patch_shape)\n",
    "\n",
    "    patches = []\n",
    "\n",
    "    for i in range(num_patches_x):\n",
    "        for j in range(num_patches_y):\n",
    "            patch = arr_out[\n",
    "                i * patch_shape[0] : min((i + 1) * patch_shape[0], arr_out.shape[0]),\n",
    "                j * patch_shape[1] : min((j + 1) * patch_shape[1], arr_out.shape[1]),\n",
    "            ]\n",
    "            if patch.shape[0] < patch_shape[0] and patch.shape[1] == patch_shape[1]:\n",
    "                # padd with zeros in that direction\n",
    "                buffer = patch_shape[0] - patch.shape[0]\n",
    "                patch = da.pad(\n",
    "                    patch, ((0, buffer), (0, 0)), mode=\"constant\", constant_values=0\n",
    "                )\n",
    "            elif patch.shape[1] < patch_shape[1] and patch.shape[0] == patch_shape[0]:\n",
    "                buffer = patch_shape[1] - patch.shape[1]\n",
    "                patch = da.pad(\n",
    "                    patch, ((0, 0), (0, buffer)), mode=\"constant\", constant_values=0\n",
    "                )\n",
    "            elif patch.shape[0] < patch_shape[0] and patch.shape[1] < patch_shape[1]:\n",
    "                buffer_x = patch_shape[0] - patch.shape[0]\n",
    "                buffer_y = patch_shape[1] - patch.shape[1]\n",
    "                patch = da.pad(\n",
    "                    patch,\n",
    "                    ((0, buffer_x), (0, buffer_y)),\n",
    "                    mode=\"constant\",\n",
    "                    constant_values=0,\n",
    "                )\n",
    "            patch_numpy = patch.compute()\n",
    "            patches.append(patch_numpy)\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform, target_transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = cv2.imread(path, -1)\n",
    "        print(\"sample shape\", sample.shape)\n",
    "        patch = view_as_windows_new(sample, (955, 783))\n",
    "        p = []\n",
    "        for i in range(len(patch)):\n",
    "            patch[i] = cv2.cvtColor(patch[i], cv2.COLOR_GRAY2RGB)\n",
    "            patch[i] = torch.from_numpy(patch[i].astype(np.float32))\n",
    "\n",
    "            if self.transform is not None:\n",
    "                patch[i] = self.transform(patch[i])\n",
    "            if self.target_transform is not None:\n",
    "                target = self.target_transform(target)\n",
    "            p.append(patch[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransform(object):\n",
    "    def __call__(self, image_tensor):\n",
    "        image_tensor = (image_tensor - image_tensor.min()) / (\n",
    "            image_tensor.max() - image_tensor.min()\n",
    "        )\n",
    "        image_tensor = image_tensor.permute(-1, 0, 1)\n",
    "        return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_class(label):\n",
    "    # create a dictionary of labels to class\n",
    "    label_to_class = {\n",
    "        0: \"FX00_Sporadic_line_artefacts\",\n",
    "        1: \"FX02_Group_of_line_artefact\",\n",
    "        2: \"FX03_partly_brighter\",\n",
    "        3: \"FX04_group_of_defect_line\",\n",
    "        4: \"FX05_Defect_line\",\n",
    "        5: \"FX07_Stripes\",\n",
    "        6: \"Good_image\",\n",
    "    }\n",
    "    return label_to_class[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_batch(predictions):\n",
    "    unique_values = set(predictions)    \n",
    "\n",
    "    if len(unique_values) == 1:\n",
    "        return predictions[0]\n",
    "\n",
    "    elif predictions.count(4) == 3:\n",
    "        return torch.Tensor([4])\n",
    "    elif predictions.count(3) == 3:\n",
    "        return torch.Tensor([3])\n",
    "    elif predictions.count(2) == 3:\n",
    "        return torch.Tensor([2])\n",
    "    elif predictions.count(1) == 3:\n",
    "        return torch.Tensor([1])\n",
    "    elif 6 in predictions:\n",
    "        predictions = list(filter(lambda item: item != 6, predictions))\n",
    "        if 5 in predictions:\n",
    "            predictions = list(filter(lambda item: item != 5, predictions))\n",
    "            if predictions == []:\n",
    "                return torch.Tensor([5])\n",
    "            else:\n",
    "                return max(set(predictions), key=predictions.count)\n",
    "        return max(set(predictions), key=predictions.count)\n",
    "    else:\n",
    "        return max(set(predictions), key=predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image=cv2.imread('/home/woody/iwi5/iwi5095h/experiments/postprocessed/1.tif',-1)\n",
    "patches = view_as_windows_new(image, (955, 783))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "probibity = []  \n",
    "confidence = []\n",
    "for i in range(len(patches)):\n",
    "    #print('patches[i]',patches[i].shape)\n",
    "    patch=patches[i]\n",
    "    #min max normalization\n",
    "    patch = (patch - patch.min()) / (patch.max() - patch.min())\n",
    "    expanded_array = patch[np.newaxis, :, :]\n",
    "\n",
    "# Duplicate the channel to create a (3, 955, 783) array\n",
    "    patch = np.repeat(expanded_array, 3, axis=0)\n",
    "    patch = patch[np.newaxis, :, :, :]\n",
    "\n",
    "    patch = torch.from_numpy(patch.astype(np.float32))\n",
    "    patch = patch.to(device)\n",
    "    output = model_ft(patch)\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "    conf, preds = torch.max(probs, 1)\n",
    "    # _, preds = torch.max(output, 1)\n",
    "    prediction.append(preds.item())\n",
    "    confidence.append(conf.item())\n",
    "    probibity.append(probs)\n",
    "probability_list = [\n",
    "                [round(value, 1) for value in tensor[0].tolist()]\n",
    "                for tensor in probibity\n",
    "            ]\n",
    "final_prediction = classify_batch(prediction)\n",
    "\n",
    "print(\n",
    "    \"prediction and its confidence\", classify_batch(prediction), np.mean(confidence)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_patch(\n",
    "    data, prediction, confidence,  final_prediction,target\n",
    "):\n",
    "    num_patches = len(data)\n",
    "    x = int(np.ceil(np.sqrt(num_patches)))\n",
    "    y = int(np.ceil(num_patches / x))\n",
    "    fig, axes = plt.subplots(x, y, figsize=(12, 6))  # Adjust figsize as needed\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "\n",
    "    for i in range(num_patches):\n",
    "        patch = data[i]\n",
    "\n",
    "        if len(axes.shape) == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i // y, i % y]\n",
    "        ax.imshow(patch, cmap=\"gray\")\n",
    "        ax.set_title(f\"Patch {i+1}\")\n",
    "        ax.axis(\"off\")  # Turn off axis labels and ticks\n",
    "\n",
    "        # Calculate text position\n",
    "        text_x = 0.5\n",
    "        text_y_prob = 5  # Place probability above the image\n",
    "        text_y_confidence = -0.15  # Place confidence below the image\n",
    "\n",
    "        # ax.text(text_x, text_y_prob, f\"Probability: {probability[i]}\", ha=\"center\")\n",
    "        ax.text(text_x, text_y_prob, f\"Conf: {confidence[i]}\", ha=\"center\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Final Prediction: {label_to_class(final_prediction.item())} \\n Target: {label_to_class(target.item())}\"\n",
    "    )\n",
    "    plt.imshow(fig,cmap='gray')\n",
    "    #plt.savefig(os.path.join(r\"experiments\\postprocessed\\results\", 'A.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = len(patches)\n",
    "print(\"num_patches\", num_patches)\n",
    "\n",
    "y = int(np.ceil(np.sqrt(num_patches)))\n",
    "x = int(np.ceil(num_patches / y))\n",
    "fig, axes = plt.subplots(x, y, figsize=(12, 12),gridspec_kw={\"top\": 0.95})  # Adjust figsize as needed\n",
    "fig.suptitle(\n",
    "    \" Target: 'FX00_Sporadic_line_artefacts' \"\n",
    ")\n",
    "indiviual_prediction=[label_to_class(p) for p in prediction]\n",
    "for i in range(num_patches):\n",
    "    ax = axes[i // y, i % y]\n",
    "    ax.imshow(patches[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Patch {i+1}\")\n",
    "    ax.text(0.5, -0.06, f'Prob: {probability_list[i]}', ha='center',va='bottom', transform=ax.transAxes)\n",
    "    ax.text(0.5, -0.07, f'Prediction: {indiviual_prediction[i]}', ha='center',va='top', transform=ax.transAxes)\n",
    "    ax.axis(\"off\")  # Turn off axis labels and ticks\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
